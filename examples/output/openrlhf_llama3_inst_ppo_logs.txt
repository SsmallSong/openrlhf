++ read -r -d '' training_commands
++ [[ '' != \s\l\u\r\m ]]
++ deepspeed ../train_ppo.py --pretrain meta-llama/Meta-Llama-3-8B-Instruct --reward_pretrain OpenLLMAI/Llama-3-8b-rm-mixture --save_path /root/.cache/huggingface/hub/7b_llama3_inst_ppo_openrlhf --save_steps 15 --logging_steps 1 --eval_steps -1 --micro_train_batch_size 2 --train_batch_size 128 --micro_rollout_batch_size 4 --rollout_batch_size 1024 --max_epochs 1 --prompt_max_len 512 --generate_max_len 256 --zero_stage 2 --bf16 --actor_learning_rate 5e-7 --critic_learning_rate 9e-6 --init_kl_coef 0.01 --prompt_data princeton-nlp/llama3-ultrafeedback --prompt_data_probs 1.0 --max_samples 162000 --normalize_reward --actor_init_on_gpu --adam_offload --gradient_checkpointing --apply_chat_template --input_key prompt
[2024-07-02 10:24:54,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-02 10:24:55,256] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-07-02 10:24:55,256] [INFO] [runner.py:568:main] cmd = /usr/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None ../train_ppo.py --pretrain meta-llama/Meta-Llama-3-8B-Instruct --reward_pretrain OpenLLMAI/Llama-3-8b-rm-mixture --save_path /root/.cache/huggingface/hub/7b_llama3_inst_ppo_openrlhf --save_steps 15 --logging_steps 1 --eval_steps -1 --micro_train_batch_size 2 --train_batch_size 128 --micro_rollout_batch_size 4 --rollout_batch_size 1024 --max_epochs 1 --prompt_max_len 512 --generate_max_len 256 --zero_stage 2 --bf16 --actor_learning_rate 5e-7 --critic_learning_rate 9e-6 --init_kl_coef 0.01 --prompt_data princeton-nlp/llama3-ultrafeedback --prompt_data_probs 1.0 --max_samples 162000 --normalize_reward --actor_init_on_gpu --adam_offload --gradient_checkpointing --apply_chat_template --input_key prompt
[2024-07-02 10:24:57,251] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-02 10:24:57,831] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.stable.20231214+cuda12.3
[2024-07-02 10:24:57,831] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2024-07-02 10:24:57,831] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2024-07-02 10:24:57,831] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2024-07-02 10:24:57,831] [INFO] [launch.py:163:main] dist_world_size=4
[2024-07-02 10:24:57,831] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2024-07-02 10:24:57,832] [INFO] [launch.py:253:main] process 64271 spawned with command: ['/usr/bin/python', '-u', '../train_ppo.py', '--local_rank=0', '--pretrain', 'meta-llama/Meta-Llama-3-8B-Instruct', '--reward_pretrain', 'OpenLLMAI/Llama-3-8b-rm-mixture', '--save_path', '/root/.cache/huggingface/hub/7b_llama3_inst_ppo_openrlhf', '--save_steps', '15', '--logging_steps', '1', '--eval_steps', '-1', '--micro_train_batch_size', '2', '--train_batch_size', '128', '--micro_rollout_batch_size', '4', '--rollout_batch_size', '1024', '--max_epochs', '1', '--prompt_max_len', '512', '--generate_max_len', '256', '--zero_stage', '2', '--bf16', '--actor_learning_rate', '5e-7', '--critic_learning_rate', '9e-6', '--init_kl_coef', '0.01', '--prompt_data', 'princeton-nlp/llama3-ultrafeedback', '--prompt_data_probs', '1.0', '--max_samples', '162000', '--normalize_reward', '--actor_init_on_gpu', '--adam_offload', '--gradient_checkpointing', '--apply_chat_template', '--input_key', 'prompt']
[2024-07-02 10:24:57,833] [INFO] [launch.py:253:main] process 64272 spawned with command: ['/usr/bin/python', '-u', '../train_ppo.py', '--local_rank=1', '--pretrain', 'meta-llama/Meta-Llama-3-8B-Instruct', '--reward_pretrain', 'OpenLLMAI/Llama-3-8b-rm-mixture', '--save_path', '/root/.cache/huggingface/hub/7b_llama3_inst_ppo_openrlhf', '--save_steps', '15', '--logging_steps', '1', '--eval_steps', '-1', '--micro_train_batch_size', '2', '--train_batch_size', '128', '--micro_rollout_batch_size', '4', '--rollout_batch_size', '1024', '--max_epochs', '1', '--prompt_max_len', '512', '--generate_max_len', '256', '--zero_stage', '2', '--bf16', '--actor_learning_rate', '5e-7', '--critic_learning_rate', '9e-6', '--init_kl_coef', '0.01', '--prompt_data', 'princeton-nlp/llama3-ultrafeedback', '--prompt_data_probs', '1.0', '--max_samples', '162000', '--normalize_reward', '--actor_init_on_gpu', '--adam_offload', '--gradient_checkpointing', '--apply_chat_template', '--input_key', 'prompt']
[2024-07-02 10:24:57,834] [INFO] [launch.py:253:main] process 64273 spawned with command: ['/usr/bin/python', '-u', '../train_ppo.py', '--local_rank=2', '--pretrain', 'meta-llama/Meta-Llama-3-8B-Instruct', '--reward_pretrain', 'OpenLLMAI/Llama-3-8b-rm-mixture', '--save_path', '/root/.cache/huggingface/hub/7b_llama3_inst_ppo_openrlhf', '--save_steps', '15', '--logging_steps', '1', '--eval_steps', '-1', '--micro_train_batch_size', '2', '--train_batch_size', '128', '--micro_rollout_batch_size', '4', '--rollout_batch_size', '1024', '--max_epochs', '1', '--prompt_max_len', '512', '--generate_max_len', '256', '--zero_stage', '2', '--bf16', '--actor_learning_rate', '5e-7', '--critic_learning_rate', '9e-6', '--init_kl_coef', '0.01', '--prompt_data', 'princeton-nlp/llama3-ultrafeedback', '--prompt_data_probs', '1.0', '--max_samples', '162000', '--normalize_reward', '--actor_init_on_gpu', '--adam_offload', '--gradient_checkpointing', '--apply_chat_template', '--input_key', 'prompt']
[2024-07-02 10:24:57,834] [INFO] [launch.py:253:main] process 64274 spawned with command: ['/usr/bin/python', '-u', '../train_ppo.py', '--local_rank=3', '--pretrain', 'meta-llama/Meta-Llama-3-8B-Instruct', '--reward_pretrain', 'OpenLLMAI/Llama-3-8b-rm-mixture', '--save_path', '/root/.cache/huggingface/hub/7b_llama3_inst_ppo_openrlhf', '--save_steps', '15', '--logging_steps', '1', '--eval_steps', '-1', '--micro_train_batch_size', '2', '--train_batch_size', '128', '--micro_rollout_batch_size', '4', '--rollout_batch_size', '1024', '--max_epochs', '1', '--prompt_max_len', '512', '--generate_max_len', '256', '--zero_stage', '2', '--bf16', '--actor_learning_rate', '5e-7', '--critic_learning_rate', '9e-6', '--init_kl_coef', '0.01', '--prompt_data', 'princeton-nlp/llama3-ultrafeedback', '--prompt_data_probs', '1.0', '--max_samples', '162000', '--normalize_reward', '--actor_init_on_gpu', '--adam_offload', '--gradient_checkpointing', '--apply_chat_template', '--input_key', 'prompt']
Traceback (most recent call last):
  File "/openrlhf/examples/scripts/../train_ppo.py", line 12, in <module>
    from openrlhf.models import Actor, get_llm_for_sequence_regression
  File "/root/.local/lib/python3.10/site-packages/openrlhf/models/__init__.py", line 1, in <module>
    from .actor import Actor
  File "/root/.local/lib/python3.10/site-packages/openrlhf/models/actor.py", line 142
    attention_mask = (sequences.ne(eos_token_id[0]) & (sequences.ne(eos_token_id[1]) & sequences.ne(pad_token_id)).to(dtype=torch.long)
                     ^
SyntaxError: '(' was never closed
Traceback (most recent call last):
  File "/openrlhf/examples/scripts/../train_ppo.py", line 12, in <module>
    from openrlhf.models import Actor, get_llm_for_sequence_regression
  File "/root/.local/lib/python3.10/site-packages/openrlhf/models/__init__.py", line 1, in <module>
    from .actor import Actor
  File "/root/.local/lib/python3.10/site-packages/openrlhf/models/actor.py", line 142
    attention_mask = (sequences.ne(eos_token_id[0]) & (sequences.ne(eos_token_id[1]) & sequences.ne(pad_token_id)).to(dtype=torch.long)
                     ^
SyntaxError: '(' was never closed
Traceback (most recent call last):
  File "/openrlhf/examples/scripts/../train_ppo.py", line 12, in <module>
    from openrlhf.models import Actor, get_llm_for_sequence_regression
  File "/root/.local/lib/python3.10/site-packages/openrlhf/models/__init__.py", line 1, in <module>
    from .actor import Actor
  File "/root/.local/lib/python3.10/site-packages/openrlhf/models/actor.py", line 142
    attention_mask = (sequences.ne(eos_token_id[0]) & (sequences.ne(eos_token_id[1]) & sequences.ne(pad_token_id)).to(dtype=torch.long)
                     ^
SyntaxError: '(' was never closed
Traceback (most recent call last):
  File "/openrlhf/examples/scripts/../train_ppo.py", line 12, in <module>
    from openrlhf.models import Actor, get_llm_for_sequence_regression
  File "/root/.local/lib/python3.10/site-packages/openrlhf/models/__init__.py", line 1, in <module>
    from .actor import Actor
  File "/root/.local/lib/python3.10/site-packages/openrlhf/models/actor.py", line 142
    attention_mask = (sequences.ne(eos_token_id[0]) & (sequences.ne(eos_token_id[1]) & sequences.ne(pad_token_id)).to(dtype=torch.long)
                     ^
SyntaxError: '(' was never closed
[2024-07-02 10:25:02,840] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 64271
[2024-07-02 10:25:02,841] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 64272
[2024-07-02 10:25:02,841] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 64273
[2024-07-02 10:25:02,842] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 64274
[2024-07-02 10:25:02,842] [ERROR] [launch.py:322:sigkill_handler] ['/usr/bin/python', '-u', '../train_ppo.py', '--local_rank=3', '--pretrain', 'meta-llama/Meta-Llama-3-8B-Instruct', '--reward_pretrain', 'OpenLLMAI/Llama-3-8b-rm-mixture', '--save_path', '/root/.cache/huggingface/hub/7b_llama3_inst_ppo_openrlhf', '--save_steps', '15', '--logging_steps', '1', '--eval_steps', '-1', '--micro_train_batch_size', '2', '--train_batch_size', '128', '--micro_rollout_batch_size', '4', '--rollout_batch_size', '1024', '--max_epochs', '1', '--prompt_max_len', '512', '--generate_max_len', '256', '--zero_stage', '2', '--bf16', '--actor_learning_rate', '5e-7', '--critic_learning_rate', '9e-6', '--init_kl_coef', '0.01', '--prompt_data', 'princeton-nlp/llama3-ultrafeedback', '--prompt_data_probs', '1.0', '--max_samples', '162000', '--normalize_reward', '--actor_init_on_gpu', '--adam_offload', '--gradient_checkpointing', '--apply_chat_template', '--input_key', 'prompt'] exits with return code = 1
